# ==========================================
# backend/app/api/llm/services/hybrid_conversation_service.py
# ==========================================

import logging
from typing import Optional, Tuple, Dict, Any
from sqlalchemy.orm import Session
from langchain_core.messages import HumanMessage

from ..providers.base_provider import BaseLLMProvider
from ..tools.functions import get_tools, set_db_session
from ..services.rag_service import RAGService
from ..multiagent.orchestrator import MultiAgentOrchestrator
from ..multiagent.config import MultiAgentConfig
from ..multiagent.langgraph_implementation import LangGraphFinancialMultiAgent, LANGGRAPH_AVAILABLE

logger = logging.getLogger(__name__)


class HybridConversationService:
    """
    ServiÃ§o hÃ­brido que usa LangGraph quando disponÃ­vel e apropriado,
    ou fallback para implementaÃ§Ã£o customizada
    """
    
    def __init__(self, llm_provider: BaseLLMProvider, rag_service: RAGService):
        self.llm_provider = llm_provider
        self.rag_service = rag_service
        self._tools = get_tools()
        
        # ConfiguraÃ§Ã£o multiagentes customizada
        self.multiagent_config = MultiAgentConfig()
        self.custom_orchestrator = MultiAgentOrchestrator(
            tools=self._tools,
            llm_provider=llm_provider,
            config=self.multiagent_config
        )
        
        # LangGraph (se disponÃ­vel)
        self.langgraph_agent = None
        if LANGGRAPH_AVAILABLE:
            try:
                self.langgraph_agent = LangGraphFinancialMultiAgent(llm_provider)
                logger.info("LangGraph MultiAgent inicializado com sucesso")
            except Exception as e:
                logger.warning(f"Falha ao inicializar LangGraph: {str(e)}. Usando implementaÃ§Ã£o customizada.")
        
        # Vincula ferramentas ao LLM
        self.llm_provider.bind_tools(self._tools)
        
        # EstratÃ©gias de escolha de implementaÃ§Ã£o
        self.complexity_threshold = 3  # NÃºmero de tool_calls para considerar "complexo"
        self.prefer_langgraph = True  # Preferir LangGraph quando disponÃ­vel
    
    def _should_use_langgraph(self, tool_calls: list, user_query: str) -> bool:
        """Decide se deve usar LangGraph ou implementaÃ§Ã£o customizada"""
        
        if not self.langgraph_agent or not self.prefer_langgraph:
            return False
        
        # CritÃ©rios para usar LangGraph:
        
        # 1. Queries complexas com mÃºltiplas ferramentas
        if len(tool_calls) >= self.complexity_threshold:
            logger.info(f"Usando LangGraph: {len(tool_calls)} tool calls (complexidade alta)")
            return True
        
        # 2. Queries que indicam fluxos complexos
        complex_keywords = [
            "anÃ¡lise completa", "relatÃ³rio detalhado", "avaliaÃ§Ã£o integral",
            "mÃºltiplas anÃ¡lises", "comparativo", "benchmarking",
            "risco e retorno", "anÃ¡lise de cenÃ¡rios"
        ]
        
        if any(keyword in user_query.lower() for keyword in complex_keywords):
            logger.info("Usando LangGraph: query indica anÃ¡lise complexa")
            return True
        
        # 3. DependÃªncias entre ferramentas detectadas
        dependency_patterns = [
            ("get_financial_data", "calculate_metrics"),
            ("calculate_metrics", "analyze_portfolio"),
            ("analyze_portfolio", "risk_assessment")
        ]
        
        tool_names = [call["name"] for call in tool_calls]
        for dep1, dep2 in dependency_patterns:
            if dep1 in tool_names and dep2 in tool_names:
                logger.info("Usando LangGraph: dependÃªncias complexas detectadas")
                return True
        
        # 4. Para queries simples, usar implementaÃ§Ã£o customizada (mais rÃ¡pida)
        logger.info("Usando implementaÃ§Ã£o customizada: query simples")
        return False
    
    async def process_conversation(
        self, 
        message: str, 
        user_id: str, 
        db_session: Session
    ) -> Tuple[str, str]:
        """
        Processa conversa usando estratÃ©gia hÃ­brida
        """
        logger.info(f"Processando mensagem hÃ­brida do usuÃ¡rio {user_id}: {message}")
        
        try:
            # 1. Configura sessÃ£o do banco
            set_db_session(db_session)
            
            # 2. Busca contexto RAG
            context = await self.rag_service.get_relevant_context(message)
            logger.info(f"Contexto RAG: {len(context)} caracteres")
            
            # 3. Primeira invocaÃ§Ã£o do LLM para identificar ferramentas necessÃ¡rias
            system_prompt = self._create_hybrid_system_prompt(context)
            messages = [
                HumanMessage(content=system_prompt),
                HumanMessage(content=message),
            ]
            
            response = await self.llm_provider.invoke(messages)
            
            final_response_text = ""
            
            # 4. Processa baseado na presenÃ§a de tool_calls
            if hasattr(response, 'tool_calls') and response.tool_calls:
                # Decide qual implementaÃ§Ã£o usar
                use_langgraph = self._should_use_langgraph(response.tool_calls, message)
                
                if use_langgraph:
                    final_response_text = await self._process_with_langgraph(
                        message, user_id, context, response, messages
                    )
                else:
                    final_response_text = await self._process_with_custom_orchestrator(
                        response, messages
                    )
            else:
                # Resposta direta
                final_response_text = response.content
                logger.info("Resposta direta sem ferramentas")
            
            # 5. Salva conversa
            await self.rag_service.save_conversation(
                user_id=user_id,
                question=message,
                answer=final_response_text,
                context=context
            )
            
            return final_response_text.strip(), context
            
        except Exception as e:
            logger.error(f"Erro no processamento hÃ­brido: {str(e)}", exc_info=True)
            return "Desculpe, ocorreu um erro ao processar sua solicitaÃ§Ã£o. Tente novamente.", ""
    
    async def _process_with_langgraph(
        self, 
        message: str, 
        user_id: str, 
        context: str,
        response,
        messages
    ) -> str:
        """Processa usando LangGraph"""
        
        logger.info("Processando com LangGraph")
        
        try:
            result = await self.langgraph_agent.process_financial_query(
                user_query=message,
                user_id=user_id,
                context=context
            )
            
            response_text = result.get("response", "")
            execution_summary = result.get("execution_summary", {})
            
            # Log de performance
            if execution_summary:
                success_rate = execution_summary.get("success_rate", 0)
                agents_used = len(result.get("agents_completed", []))
                logger.info(f"LangGraph concluÃ­do - Agentes: {agents_used}, Sucesso: {success_rate}%")
            
            return response_text
            
        except Exception as e:
            logger.error(f"Erro no LangGraph, fallback para implementaÃ§Ã£o customizada: {str(e)}")
            # Fallback para implementaÃ§Ã£o customizada
            return await self._process_with_custom_orchestrator(response, messages)
    
    async def _process_with_custom_orchestrator(self, response, messages) -> str:
        """Processa usando orquestrador customizado"""
        
        logger.info("Processando com orquestrador customizado")
        
        try:
            # Usa a implementaÃ§Ã£o original
            execution_summary = await self.custom_orchestrator.coordinate_agents(response.tool_calls)
            
            # Converte para tool messages
            tool_messages = self._create_tool_messages_from_summary(execution_summary, response.tool_calls)
            
            # Atualiza mensagens e solicita resposta final
            messages.extend([response] + tool_messages)
            
            if execution_summary.failed_tasks > 0:
                execution_report = self._create_execution_report(execution_summary)
                messages.append(HumanMessage(content=f"RELATÃ“RIO: {execution_report}"))
            
            final_response = await self.llm_provider.invoke(messages)
            
            logger.info(f"Orquestrador customizado concluÃ­do - Sucesso: {execution_summary.success_rate:.1f}%")
            
            return final_response.content
            
        except Exception as e:
            logger.error(f"Erro no orquestrador customizado: {str(e)}")
            return f"Erro no processamento multiagentes: {str(e)}"
    
    def _create_hybrid_system_prompt(self, context: str) -> str:
        """Cria prompt otimizado para o sistema hÃ­brido"""
        
        system_features = []
        
        if self.langgraph_agent:
            system_features.append("- Sistema LangGraph para anÃ¡lises complexas com fluxos otimizados")
        
        system_features.append("- Orquestrador customizado para operaÃ§Ãµes especializadas")
        system_features.append("- SeleÃ§Ã£o automÃ¡tica da melhor estratÃ©gia de processamento")
        
        return f"""
        VocÃª Ã© um assistente financeiro avanÃ§ado com sistema multiagentes hÃ­brido.

        CAPACIDADES DO SISTEMA:
        {chr(10).join(system_features)}

        AGENTES ESPECIALIZADOS DISPONÃVEIS:
        - ðŸ“Š Recuperador de Dados: informaÃ§Ãµes financeiras, mercado, empresas
        - ðŸ§® Calculadora: mÃ©tricas, ratios, retornos, valuations
        - ðŸ“ˆ Analista Financeiro: insights, anÃ¡lises estratÃ©gicas, recomendaÃ§Ãµes
        - âš ï¸ Avaliador de Riscos: VaR, stress testing, anÃ¡lise de volatilidade
        - âœ… Validador: consistÃªncia de dados e resultados
        - ðŸ“‹ Compliance: verificaÃ§Ãµes regulatÃ³rias

        OTIMIZAÃ‡Ã•ES AUTOMÃTICAS:
        - ExecuÃ§Ã£o paralela quando possÃ­vel
        - DetecÃ§Ã£o inteligente de dependÃªncias
        - ValidaÃ§Ã£o automÃ¡tica de resultados
        - Retry automÃ¡tico em falhas transitÃ³rias
        - SeleÃ§Ã£o da estratÃ©gia mais eficiente

        CONTEXTO:
        {context or "Nenhum contexto especÃ­fico disponÃ­vel."}
        """
    
    def _create_tool_messages_from_summary(self, summary, tool_calls):
        """Converte sumÃ¡rio de execuÃ§Ã£o para ToolMessages (implementaÃ§Ã£o simplificada)"""
        # Reutiliza a lÃ³gica do ConversationService original
        from langchain_core.messages import ToolMessage
        import json
        
        tool_messages = []
        tool_call_map = {call["name"]: call.get("id", "unknown") for call in tool_calls}
        
        for tool_call in tool_calls:
            tool_name = tool_call["name"]
            tool_call_id = tool_call_map.get(tool_name, "unknown")
            
            content = json.dumps({
                "tool_name": tool_name,
                "status": "processed",
                "execution_summary": summary.to_dict()
            }, ensure_ascii=False)
            
            tool_messages.append(ToolMessage(content=content, tool_call_id=tool_call_id))
        
        return tool_messages
    
    def _create_execution_report(self, summary) -> str:
        """Cria relatÃ³rio de execuÃ§Ã£o"""
        return f"""
        ExecuÃ§Ã£o concluÃ­da:
        - Tarefas: {summary.total_tasks}
        - Sucessos: {summary.successful_tasks}  
        - Taxa: {summary.success_rate:.1f}%
        - Tempo: {summary.total_execution_time:.2f}s
        """
    def get_provider_info(self) -> dict:
        """Retorna informaÃ§Ãµes sobre o provedor LLM atual"""
        return self.llm_provider.get_model_info()
    
    def get_system_info(self) -> Dict[str, Any]:
        """Retorna informaÃ§Ãµes sobre o sistema hÃ­brido"""
        info = {
            "type": "hybrid_multiagent_system",
            "langgraph_available": self.langgraph_agent is not None,
            "custom_orchestrator": True,
            "tools_count": len(self._tools),
            "complexity_threshold": self.complexity_threshold,
            "prefer_langgraph": self.prefer_langgraph
        }
        
        if self.langgraph_agent:
            info["langgraph_features"] = [
                "state_management",
                "conditional_routing", 
                "parallel_execution",
                "checkpoints",
                "visual_debugging"
            ]
        
        info["custom_features"] = [
            "specialized_validators",
            "performance_analytics", 
            "retry_mechanisms",
            "dependency_detection",
            "execution_statistics"
        ]
        
        return info
    
    async def health_check(self) -> Dict[str, Any]:
        """Health check do sistema hÃ­brido"""
        status = {
            "service": "hybrid_multiagent_conversation",
            "status": "healthy",
            "llm_provider": self.llm_provider.get_model_info(),
            "tools_available": len(self._tools),
            "implementations": {
                "custom_orchestrator": "available",
                "langgraph": "available" if self.langgraph_agent else "unavailable"
            }
        }
        
        try:
            # Testa LLM
            test_messages = [HumanMessage(content="Health check")]
            await self.llm_provider.invoke(test_messages)
            status["llm_connection"] = "healthy"
            
            # Testa orquestrador customizado
            custom_stats = self.custom_orchestrator.get_statistics()
            status["custom_orchestrator_stats"] = custom_stats
            
            # InformaÃ§Ãµes do sistema
            status["system_info"] = self.get_system_info()
            
        except Exception as e:
            status["status"] = "unhealthy"
            status["error"] = str(e)
        
        return status
    
    def configure_strategy(self, 
                          complexity_threshold: int = None, 
                          prefer_langgraph: bool = None):
        """Permite configurar a estratÃ©gia de seleÃ§Ã£o"""
        if complexity_threshold is not None:
            self.complexity_threshold = complexity_threshold
            
        if prefer_langgraph is not None:
            self.prefer_langgraph = prefer_langgraph
        
        logger.info(f"EstratÃ©gia atualizada - Threshold: {self.complexity_threshold}, "
                   f"Preferir LangGraph: {self.prefer_langgraph}")


# ==========================================
# BENCHMARK E COMPARAÃ‡ÃƒO DE PERFORMANCE
# ==========================================

class MultiAgentBenchmark:
    """Classe para benchmark entre diferentes implementaÃ§Ãµes"""
    
    def __init__(self, hybrid_service: HybridConversationService):
        self.hybrid_service = hybrid_service
        self.benchmark_results = []
    
    async def run_benchmark(self, test_queries: list, iterations: int = 3):
        """Executa benchmark comparativo"""
        
        for query in test_queries:
            query_results = {
                "query": query,
                "langgraph_results": [],
                "custom_results": []
            }
            
            for i in range(iterations):
                # ForÃ§a uso do LangGraph
                original_prefer = self.hybrid_service.prefer_langgraph
                self.hybrid_service.prefer_langgraph = True
                
                try:
                    import time
                    start_time = time.time()
                    
                    # Simula processamento (sem salvar no banco)
                    # Implementar lÃ³gica de benchmark aqui
                    
                    execution_time = time.time() - start_time
                    query_results["langgraph_results"].append({
                        "iteration": i + 1,
                        "execution_time": execution_time,
                        "success": True
                    })
                    
                except Exception as e:
                    query_results["langgraph_results"].append({
                        "iteration": i + 1,
                        "execution_time": 0,
                        "success": False,
                        "error": str(e)
                    })
                
                # ForÃ§a uso do customizado
                self.hybrid_service.prefer_langgraph = False
                
                try:
                    start_time = time.time()
                    
                    # Simula processamento customizado
                    
                    execution_time = time.time() - start_time
                    query_results["custom_results"].append({
                        "iteration": i + 1,
                        "execution_time": execution_time,
                        "success": True
                    })
                    
                except Exception as e:
                    query_results["custom_results"].append({
                        "iteration": i + 1,
                        "execution_time": 0,
                        "success": False,
                        "error": str(e)
                    })
                
                # Restaura configuraÃ§Ã£o original
                self.hybrid_service.prefer_langgraph = original_prefer
            
            self.benchmark_results.append(query_results)
        
        return self.analyze_benchmark_results()
    
    def analyze_benchmark_results(self):
        """Analisa resultados do benchmark"""
        if not self.benchmark_results:
            return {"message": "Nenhum benchmark executado"}
        
        analysis = {
            "total_queries": len(self.benchmark_results),
            "langgraph_performance": {
                "average_time": 0,
                "success_rate": 0,
                "total_executions": 0
            },
            "custom_performance": {
                "average_time": 0,
                "success_rate": 0,
                "total_executions": 0
            },
            "recommendation": ""
        }
        
        # Calcula estatÃ­sticas
        lg_times = []
        lg_successes = 0
        custom_times = []
        custom_successes = 0
        
        for result in self.benchmark_results:
            for lg_result in result["langgraph_results"]:
                if lg_result["success"]:
                    lg_times.append(lg_result["execution_time"])
                    lg_successes += 1
            
            for custom_result in result["custom_results"]:
                if custom_result["success"]:
                    custom_times.append(custom_result["execution_time"])
                    custom_successes += 1
        
        # AnÃ¡lise LangGraph
        if lg_times:
            analysis["langgraph_performance"]["average_time"] = sum(lg_times) / len(lg_times)
        analysis["langgraph_performance"]["success_rate"] = (lg_successes / (len(self.benchmark_results) * 3)) * 100
        analysis["langgraph_performance"]["total_executions"] = len(self.benchmark_results) * 3
        
        # AnÃ¡lise Custom
        if custom_times:
            analysis["custom_performance"]["average_time"] = sum(custom_times) / len(custom_times)
        analysis["custom_performance"]["success_rate"] = (custom_successes / (len(self.benchmark_results) * 3)) * 100
        analysis["custom_performance"]["total_executions"] = len(self.benchmark_results) * 3
        
        # RecomendaÃ§Ã£o
        lg_avg = analysis["langgraph_performance"]["average_time"]
        custom_avg = analysis["custom_performance"]["average_time"]
        lg_success = analysis["langgraph_performance"]["success_rate"]
        custom_success = analysis["custom_performance"]["success_rate"]
        
        if lg_success > custom_success and lg_avg < custom_avg * 1.5:
            analysis["recommendation"] = "LangGraph recomendado - melhor sucesso e performance aceitÃ¡vel"
        elif custom_avg < lg_avg * 0.7:
            analysis["recommendation"] = "ImplementaÃ§Ã£o customizada recomendada - significativamente mais rÃ¡pida"
        else:
            analysis["recommendation"] = "EstratÃ©gia hÃ­brida recomendada - usar baseado na complexidade"
        
        return analysis


# ==========================================
# EXEMPLO DE USO
# ==========================================

"""
# Exemplo de configuraÃ§Ã£o e uso:

# InicializaÃ§Ã£o
llm_provider = SeuLLMProvider()
rag_service = SeuRAGService()

# ServiÃ§o hÃ­brido
hybrid_service = HybridConversationService(llm_provider, rag_service)

# Processamento automÃ¡tico (escolhe a melhor estratÃ©gia)
response, context = await hybrid_service.process_conversation(
    message="FaÃ§a uma anÃ¡lise completa do portfÃ³lio XYZ incluindo riscos e recomendaÃ§Ãµes",
    user_id="user_123",
    db_session=session
)

# ConfiguraÃ§Ã£o manual da estratÃ©gia
hybrid_service.configure_strategy(
    complexity_threshold=2,  # Usar LangGraph com 2+ ferramentas
    prefer_langgraph=True    # Preferir LangGraph quando disponÃ­vel
)

# Benchmark comparativo
benchmark = MultiAgentBenchmark(hybrid_service)
test_queries = [
    "Calcule as mÃ©tricas do portfolio ABC",
    "AnÃ¡lise completa de risco e retorno da empresa XYZ",
    "Comparativo de performance entre fundos A, B e C"
]

results = await benchmark.run_benchmark(test_queries, iterations=3)
print(f"RecomendaÃ§Ã£o: {results['recommendation']}")
"""